Human Activity Recognition
Overview

Human Activity Recognition (HAR) is a machine learning experiment aimed at classifying human activities using a 2D pose time series dataset and an LSTM (Long Short-Term Memory) RNN. The experiment explores the potential of 2D pose data (as opposed to 3D pose or raw 2D images) for accurate activity recognition and behavior prediction, specifically for human and animal activity recognition in environments where RGB cameras are used.

This work is a step towards better interaction with autonomous mobile robots by classifying the current behavior of a subject and predicting their next likely state.

Objectives

The main objectives of this experiment are:

Compare 2D vs. 3D Pose for Activity Recognition: To test if 2D pose estimation can provide comparable accuracy to 3D pose for activity recognition, enabling the use of standard RGB cameras instead of more complex RGBD cameras or motion capture systems.

Evaluate 2D Pose vs. Raw RGB Images: To determine if 2D pose can be as accurate as using raw RGB images for activity recognition, potentially allowing for smaller models that can operate efficiently on limited datasets.

Future Behavior Prediction: To verify if 2D pose data can be used for predicting future behavioral states from motion, laying the foundation for real-time behavior prediction in animals or humans.

Dataset Overview

The dataset used for this project consists of pose estimations from the OpenPose software applied to a subset of the Berkeley Multimodal Human Action Database (MHAD).

The dataset contains 12 subjects performing 6 different actions across 5 repetitions, filmed from 4 different angles. The actions performed are:

Jumping

Jumping Jacks

Boxing

Waving with Two Hands

Waving with One Hand

Clapping Hands

In total, there are 1438 videos made up of 211,200 individual frames, with each video representing one of the actions repeated five times.

Technical Details
Key Components:

Model: Long Short-Term Memory (LSTM) neural networks used for classifying human and animal activities.

Data: 2D pose data generated by OpenPose.

Preprocessing: The data is processed to create time series input features representing the pose of the subject across multiple frames.

Modifications:

Adapted the network based on Guillaume Chevalier's "LSTMs for Human Activity Recognition (2016)" and the Berkeley MHAD dataset, including modifications for handling large datasets, class ordering, and random sampling.

Results:

The model is expected to classify activities with a high degree of accuracy based on 2D pose data, demonstrating the efficiency of using 2D poses for human and animal behavior recognition in real-time applications.
